{
  "hash": "4288bc7bdc6b6589cbbcb3538338172e",
  "result": {
    "markdown": "---\ntitle: \"Jumping into curve fitting ! 🚀\"\nauthor: \"Arno V\"\ndate: \"2023-02-04\"\ncategories: [julia, code, analysis, economics]\nimage: \"qqplot-ex.png\"\n---\n\n# Let's fit some univariate distributions 🚀\n\nLast time we were just looking at the relative income distribution. This time we'll try to fit some curves to it.  \n\nThe goal is to find a parametric model $P_{\\phi}$ that fits the data well for some $\\phi$ (we'll most probably work with $\\mathbb{R}$-valued vector $\\phi$'s).  \n\nNow though I have made a clean CSV file with the simplified data, let me just grab that 😉\n\n::: {.cell context='setup' execution_count=1}\n``` {.julia .cell-code}\nusing DataFrames, DataFramesMeta, BrowseTables, CSV\nusing Distributions, StatsPlots, Statistics\nusing Plots\nusing LaTeXStrings\n\ndf = DataFrame(CSV.File(\"C:\\\\Users\\\\arnov\\\\Documents\\\\code\\\\notebooks\\\\quarto\\\\econ\\\\data\\\\data-clean-full-latest-x-y-cdf.csv\"))\n\nscatter(\n    df.perc_mean,\n    df.rel_income,\n    label=L\"Data points $(p, i_p)$\",\n    xlabel=L\"Percentile $p$\",\n    ylabel=L\"Relative income $i_p$\",\n    size=(800, 600),\n    background_color=\"#7711d708\",\n    markersize=10,\n    markerstrokewidth=2,\n    markerstrokecolor=\"black\",\n    markeralpha=0.2,\n    markercolor=:pink,\n    legendfontsize=18,\n    guidefontsize=18,\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n![](index_files/figure-html/cell-2-output-1.svg){}\n:::\n:::\n\n\n<br>\n\n\n## The most basic model\n\nLet's start with the most basic model, any of the positive parametric distributions.\n\nWe've got three choices I can think of:\n\n* The [Gamma][1] distribution $\\Gamma(\\alpha, \\beta)$ with $\\phi = (\\alpha, \\beta)$\n* The [LogNormal][2] distribution $\\mathcal{LN}(\\mu, \\sigma)$ with $\\phi = (\\mu, \\sigma)$\n* The [Weibull distribution][3] $\\mathcal{W}(\\lambda, k)$ with $\\phi = (\\lambda, k)$\n\nWe're not going to think really hard for now, we'll just use the most basic method for fitting the curve:\n\n* dismiss that those are quantiles\n* use them as plain points to perform likelihood maximization\n\n### The Gamma distribution\n\nImportant to note that the [Distributions.jl][4] package implements the Gamma using this parametrization:\n\n$$ f(x) = \\frac{1}{\\Gamma(\\alpha) \\theta^\\alpha} x^{\\alpha - 1} e^{-\\frac{x}{\\theta}}\\qquad\\text{for } x > 0 $$\n\nThis is a small detail worth nothing 🤓. The interface to fit is the same for all: you get your data $\\vec{x} \\coloneqq [x_1, \\ldots, x_n]$ into an array and you call `fit_mle(Distribution, data)`.\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\nvalidPts = filter(x -> x .> 0, df.rel_income)\nfittedGamma = fit_mle(Gamma, validPts)\nymax = maximum(pdf.(fittedGamma,validPts))\n\n\n\nplot(\n    fittedGamma,\n    label=L\"Gamma $\\Gamma$ fit\",\n    xlabel=L\"Relative income $i_p$\",\n    ylabel=L\"Probability density $f(i_p)$\",\n    size=(800, 600),\n    color=:pink,\n    fill=(0, 0.2, :pink),\n    background_color=\"#7711d708\",\n    legendfontsize=18,\n    guidefontsize=18,\n    ylims=(0, ymax*1.1),\n    title=\"Gamma fit to the data, \\$k = $(round(fittedGamma.α, sigdigits=3)), \\\\theta = $(round(fittedGamma.θ, sigdigits=3))\\$\",\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n![](index_files/figure-html/cell-3-output-1.svg){}\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\nusing Markdown\n\nNLL = -loglikelihood(fittedGamma, validPts)\n\nls = \"\"\"\n    Alright that's pretty good, we've got our \\$\\\\Gamma\\$ fit to the data, with\n    \\$k = $(round(fittedGamma.α, sigdigits=3)),\n    \\\\theta = $(round(fittedGamma.θ, sigdigits=3))\\$\n    \n    How good is this fit though ?  \n    Let's check the log-likelihood of the data under this model. \n    \n    \n    \\$\\\\text{log}P_{\\\\phi}(\\\\vec{x}) = $(round(NLL, sigdigits=3))\\$\n    \n    \"\"\"\nMarkdown.parse(ls)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\nAlright that's pretty good, we've got our $\\Gamma$ fit to the data, with $k = 1.83, \\theta = 14.5$\n\nHow good is this fit though ?   Let's check the log-likelihood of the data under this model. \n\n$$\n\\text{log}P_{\\phi}(\\vec{x}) = 2070.0\n$$\n\n:::\n:::\n\n\n<br>\n\nIt's been a while since I actually looked at NLL values but this seems quite high. Let's check the QQ plot to see how it looks.\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\nqqplot(fittedGamma, validPts,\nlabel=L\"$\\Gamma$ fit\", xlabel=L\"Theoretical Quantiles $q$\", \nylabel=L\"Observed quantiles: Relative income $i_p$\", \nsize=(800, 600),\nbackground_color=\"#7711d708\",\nlegendfontsize=18,\nguidefontsize=18,\ncolor=:pink,\nmarkersize=5,\nmarkerstrokewidth=1,\nmarkerstrokecolor=\"purple\",\nmarkeralpha=0.3,\nmarkercolor=:pink,)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n![](index_files/figure-html/cell-5-output-1.svg){}\n:::\n:::\n\n\nUh oh, that's not good. The QQ plot is not looking good at all.  \nOut of curiosity lets see the result of the KS test.\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code}\nusing HypothesisTests\n\nks = ExactOneSampleKSTest(validPts, fittedGamma)\n\nls = \"\"\"\n    The likelihood that the data is drawn from the fitted Gamma distribution is\n\n    given by the \\$p\\$-value \\$D_n(d)\\$ where \\$d = \\\\lVert F_n - F \\\\rVert_{\\\\infty}\\$,\n\n    here:\n    \\$p = $(round(pvalue(ks, tail= :both), sigdigits=3))\\$\n    \"\"\"\nMarkdown.parse(ls)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\nThe likelihood that the data is drawn from the fitted Gamma distribution is\n\ngiven by the $p$-value $D_n(d)$ where $d = \\lVert F_n - F \\rVert_{\\infty}$,\n\nhere: $p = 8.24e-6$\n\n:::\n:::\n\n\n<br>\n\nWell that's a way to put it. The p-value is on the order of $10^{-6}$, OK. In comparison most scientific papers use a threshold for rejection of the null that's $\\approx 10^{-2}$. We're roughly $10000$ more confident here ! Let's try the other two.\n\n### The LogNormal distribution\n\nThe LogNormal is just a gaussian squished through a logarithmic post-processor, it's a bit more intuitive but there's no reason it should be better than the Gamma (a priori).\n\n::: {.cell execution_count=6}\n``` {.julia .cell-code}\nfittedLogNormal = fit_mle(LogNormal, validPts)\n\nymax = maximum(pdf.(fittedLogNormal, validPts))\n\nplot(\n    fittedLogNormal,\n    label=L\"LogNormal $\\mathcal{LN}$ fit\",\n    xlabel=L\"Relative income $i_p$\",\n    ylabel=L\"Probability density $f(i_p)$\",\n    size=(800, 600),\n    color=:pink,\n    fill=(0, 0.2, :pink),\n    background_color=\"#7711d708\",\n    legendfontsize=18,\n    ylims=(0, ymax*1.1),\n    guidefontsize=18,\n    title=\"LogNormal fit to the data, \\$\\\\mu = $(round(fittedLogNormal.μ, sigdigits=3)), \\\\sigma = $(round(fittedLogNormal.σ, sigdigits=3))\\$\",\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n![](index_files/figure-html/cell-7-output-1.svg){}\n:::\n:::\n\n\n<br>\n\nAlright, let's not have our hopes up too high. Let's check the QQ plot.\n\n::: {.cell execution_count=7}\n``` {.julia .cell-code}\nqqplot(fittedLogNormal, validPts,\nlabel=L\"$\\mathcal{LN}$ fit\", xlabel=L\"Theoretical Quantiles $q$\",\nylabel=L\"Observed quantiles: Relative income $i_p$\",\nsize=(800, 600),\nbackground_color=\"#7711d708\",\nlegendfontsize=18,\nguidefontsize=18,\ncolor=:pink,\nmarkersize=5,\nmarkerstrokewidth=1,\nmarkerstrokecolor=\"purple\",\nmarkeralpha=0.3,\nmarkercolor=:pink,)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n![](index_files/figure-html/cell-8-output-1.svg){}\n:::\n:::\n\n\n<br>\n\nThis is hilariously bad !! No use checking the KS test.\n\nLast but not least, the Weibull distribution.\n\n### The Weibull distribution\n\nWeibull is a more general version of the exponential distribution, a $W$ weibull variable is generally $W \\propto (X/\\lambda)^k$ where $X$ is a $\\lambda$-scale exponential variable.\n\n::: {.cell execution_count=8}\n``` {.julia .cell-code}\nfittedWeibull = fit_mle(Weibull, validPts)\n\nymax = maximum(pdf.(fittedWeibull, validPts ))\n\nplot(\n    fittedWeibull,\n    label=L\"Weibull $\\mathcal{W}$ fit\",\n    xlabel=L\"Relative income $i_p$\",\n    ylabel=L\"Probability density $f(i_p)$\",\n    size=(800, 600),\n    color=:pink,\n    fill=(0, 0.2, :pink),\n    background_color=\"#7711d708\",\n    legendfontsize=18,\n    guidefontsize=18,\n    ylims=(0, ymax*1.1),\n    title=\"Weibull fit to the data, \\$\\\\alpha = $(round(fittedWeibull.α, sigdigits=3)), \\\\beta = $(round(fittedWeibull.θ, sigdigits=3))\\$\",\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n![](index_files/figure-html/cell-9-output-1.svg){}\n:::\n:::\n\n\n<br>\n\nLet's check the QQ plot.\n\n::: {.cell execution_count=9}\n``` {.julia .cell-code}\nqqplot(fittedWeibull, validPts,\nlabel=L\"$\\mathcal{W}$ fit\", xlabel=L\"Theoretical Quantiles $q$\",\nylabel=L\"Observed quantiles: Relative income $i_p$\",\nsize=(800, 600),\nbackground_color=\"#7711d708\",\nlegendfontsize=18,\nguidefontsize=18,\ncolor=:pink,\nmarkersize=5,\nmarkerstrokewidth=1,\nmarkerstrokecolor=\"purple\",\nmarkeralpha=0.3,\nmarkercolor=:pink,)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n![](index_files/figure-html/cell-10-output-1.svg){}\n:::\n:::\n\n\n<br>\n\nOoohh 👀 hey there, that's not bad at all. Let's check the NLL first.\n\n::: {.cell execution_count=10}\n``` {.julia .cell-code}\nNLL = -loglikelihood(fittedWeibull, validPts)\n\nls = \"\"\"\n    The (negative) log-likelihood of the data under this model is..\n    \n    \\$\\\\text{log}P_{\\\\phi}(\\\\vec{x}) = $(round(NLL, sigdigits=3))\\$\n    \n    \"\"\"\nMarkdown.parse(ls)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\nThe (negative) log-likelihood of the data under this model is..\n\n$$\n\\text{log}P_{\\phi}(\\vec{x}) = 2050.0\n$$\n\n:::\n:::\n\n\n<br>\n\nHmm, not sure what to make of this. Let's check the KS test.\n\n::: {.cell execution_count=11}\n``` {.julia .cell-code}\nks = ExactOneSampleKSTest(validPts, fittedWeibull)\n\nls = \"\"\"\n    The likelihood that the data is drawn from the fitted Weibull distribution is\n\n    given by the \\$p\\$-value \\$D_n(d)\\$, which is equal to\n\n    \\$p = $(round(pvalue(ks, tail= :both), sigdigits=3))\\$\n    \"\"\"\nMarkdown.parse(ls)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\nThe likelihood that the data is drawn from the fitted Weibull distribution is\n\ngiven by the $p$-value $D_n(d)$, which is equal to\n\n$$\np = 4.99e-5\n$$\n\n:::\n:::\n\n\n<br>\n\nMeh, all of them get zero but the KS test is known to be a bit strict.  \n\nLet's see if we get a bit more information using the $L_2$ norm.\n\n::: {.cell execution_count=12}\n``` {.julia .cell-code}\nadWeibull = OneSampleADTest(validPts, fittedWeibull)\nksWeibull = ExactOneSampleKSTest(validPts, fittedWeibull)\n\nadGamma = OneSampleADTest(validPts, fittedGamma)\nksGamma = ExactOneSampleKSTest(validPts, fittedGamma)\n\nadLogNormal = OneSampleADTest(validPts, fittedLogNormal)\nksLogNormal = ExactOneSampleKSTest(validPts, fittedLogNormal)\n\nls = \"\"\"\n    To summarize, here are the results of the tests:\n\n    | Distribution | parameters | NLL | \\$L_2\\$ norm \\$p\\$-value | \\$L_\\\\infty\\$ norm \\$p\\$-value |\n    |:------------:|:----------:|:----------:|:--------------------:|:-------------------------:|\n    | Weibull | \\$\\\\alpha = $(round(fittedWeibull.α, sigdigits=3)), \\\\theta = $(round(fittedWeibull.θ, sigdigits=3))\\$ | $(round(-loglikelihood(fittedWeibull, validPts), sigdigits=3)) | $(round(pvalue(adWeibull), sigdigits=3)) | $(round(pvalue(ksWeibull, tail= :both), sigdigits=3)) |\n    | Gamma | \\$\\\\alpha = $(round(fittedGamma.α, sigdigits=3)), \\\\theta = $(round(fittedGamma.θ, sigdigits=3))\\$ | $(round(-loglikelihood(fittedGamma, validPts), sigdigits=3)) | $(round(pvalue(adGamma), sigdigits=3)) | $(round(pvalue(ksGamma, tail= :both), sigdigits=3)) |\n    | LogNormal | \\$\\\\mu = $(round(fittedLogNormal.μ, sigdigits=3)), \\\\sigma = $(round(fittedLogNormal.σ, sigdigits=3))\\$ | $(round(-loglikelihood(fittedLogNormal, validPts), sigdigits=3)) | $(round(pvalue(adLogNormal), sigdigits=3)) | $(round(pvalue(ksLogNormal, tail= :both), sigdigits=3)) |\n    \"\"\"\n\nMarkdown.parse(ls)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\nTo summarize, here are the results of the tests:\n\n| Distribution |           parameters           |  NLL   | $L_2$ norm $p$-value | $L_\\infty$ norm $p$-value |\n|:------------:|:------------------------------:|:------:|:--------------------:|:-------------------------:|\n|   Weibull    | $\\alpha = 1.61, \\theta = 29.4$ | 2050.0 |       0.000188       |          4.99e-5          |\n|    Gamma     | $\\alpha = 1.83, \\theta = 14.5$ | 2070.0 |       1.41e-5        |          8.24e-6          |\n|  LogNormal   |  $\\mu = 2.98, \\sigma = 0.956$  | 2160.0 |       1.21e-6        |          2.0e-8           |\n\n:::\n:::\n\n\nThat's all for today folks ! We'll try hierarchical models next time 🕵️\n\n\n[1]:https://en.wikipedia.org/wiki/Gamma_distribution\n[2]:https://en.wikipedia.org/wiki/Log-normal_distribution\n[3]:https://en.wikipedia.org/wiki/Weibull_distribution\n[4]:https://juliastats.org/Distributions.jl/stable/univariate/#Distributions.Gamma\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}