[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Arno’s Data Science snippets",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nFirst attempt at modelling using Julia\n\n\n\n\n\n\n\njulia\n\n\ncode\n\n\nanalysis\n\n\neconomics\n\n\n\n\n\n\n\n\n\n\n\nFeb 4, 2023\n\n\nArno V\n\n\n\n\n\n\n  \n\n\n\n\nWelcome to my data notebooks blog !\n\n\n\n\n\n\n\nlaunch\n\n\nblog\n\n\nhello\n\n\ncode\n\n\ndata\n\n\n\n\n\n\n\n\n\n\n\nFeb 1, 2023\n\n\nArno V\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/first-steps-julia/index.html",
    "href": "posts/first-steps-julia/index.html",
    "title": "First attempt at modelling using Julia",
    "section": "",
    "text": "A first attempt at modelling using Julia\n\n\n\n✨ Economic data 📊 , Julia 🤗 and Jupyter🪐\nThe setup : libs & data\n\n\nShow the code\nusing DataFrames, DataFramesMeta, BrowseTables, Parquet\nusing Distributions, StatsPlots, Statistics\nusing Plots\nusing LaTeXStrings\n\n\n\nImporting the data\n\n\nShow the code\ndf = DataFrame(\n    read_parquet(\"C:\\\\Users\\\\arnov\\\\Documents\\\\code\\\\notebooks\\\\quarto\\\\econ\\\\data\\\\data-clean-full-latest.parquet\"))\n\nfirst(df, 10)\n\n\n\n10×8 DataFrameRowperccountryyearrel_incomeoriginalcodenumlabelFloat64?String?Int64?Float64?String?String?Int64?String?10.1Albania20172.0D1:First decileD1First decile20.1Albania20182.0D1:First decileD1First decile30.1Albania20192.3D1:First decileD1First decile40.1Albania20202.5D1:First decileD1First decile50.1Austria19953.0D1:First decileD1First decile60.1Austria19964.0D1:First decileD1First decile70.1Austria19974.0D1:First decileD1First decile80.1Austria19984.0D1:First decileD1First decile90.1Austria19994.0D1:First decileD1First decile100.1Austria20004.0D1:First decileD1First decile\n\n\n\n\n\nWhat we aim to do\nHere we have two values, \\(Q(p)\\) and \\(p\\), where \\(p\\) is a percentile and \\(Q\\) the Quantile function.\nYou could conversely see it as \\(q\\) and \\(F(q)\\), where \\(q\\) is a quantile and \\(F\\) the CDF.\nWe want to find a decent model for \\(F\\). We’ll try a few methods first:\n\nThe classic Q-Q plot eyeballing\nThe Kolmogorov-Smirnov test (based on the \\(L_\\infty\\) norm \\(||F-\\hat{F}||_\\infty\\))\nThe so-called Anderson-Darling test (based on the \\(L_2\\) norm \\(||F-\\hat{F}||_2\\))\n\nLet’s first look at the data: the true model actually depends on \\(\\langle t, k, p \\rangle\\) (time, country and percentile), but we’ll ignore that for now.\n\n\nShow the code\ndfg = groupby(df, :rel_income)\n\ndfr = hcat(\n    combine(dfg,\n        :perc => ((p) -> quantile(p, 0.025)) => :perc_025,\n        :perc => ((p) -> quantile(p, 0.05)) => :perc_05,\n        :perc => ((p) -> quantile(p, 0.25)) => :perc_25,\n        :perc => ((p) -> quantile(p, 0.5)) => :perc_50,\n        :perc => ((p) -> quantile(p, 0.75)) => :perc_75,\n        :perc => ((p) -> quantile(p, 0.95)) => :perc_95,\n        :perc => ((p) -> quantile(p, 0.975)) => :perc_975,\n        ),\n    combine(dfg,\n        :perc => mean => :perc_mean,\n        :perc => std => :perc_std,\n        ),\n        makeunique=true\n)\n\n\n\n506×11 DataFrame481 rows omittedRowrel_incomeperc_025perc_05perc_25perc_50perc_75perc_95perc_975rel_income_1perc_meanperc_stdFloat64?Float64Float64Float64Float64Float64Float64Float64Float64?Float64Float6412.00.10.10.950.950.970.980.982.00.8870810.23835922.30.10.440.960.970.980.990.992.30.9258740.19311832.50.10.10.970.980.980.990.992.50.9141110.22806443.00.10.10.10.980.990.990.993.00.580370.44283254.00.10.10.10.10.21.01.04.00.3277480.3660263.50.10.10.10.10.990.99951.03.50.4667740.43410373.60.10.10.10.150.991.01.03.60.4325710.4207583.80.10.10.10.21.01.01.03.80.4742310.43647193.40.10.10.10.980.991.01.03.40.5643860.440106103.30.10.10.10.10.990.9941.03.30.4915070.443608113.20.10.10.10.980.991.01.03.20.6036250.439773123.10.10.10.10.980.990.990.993.10.6617070.429311133.70.10.10.10.10.991.01.03.70.3794740.406705⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮49539.31.01.01.01.01.01.01.039.31.00.049635.81.01.01.01.01.01.01.035.81.00.049734.21.01.01.01.01.01.01.034.21.00.049837.21.01.01.01.01.01.01.037.21.00.049937.61.01.01.01.01.01.01.037.61.00.050036.11.01.01.01.01.01.01.036.11.00.050133.61.01.01.01.01.01.01.033.61.00.050233.21.01.01.01.01.01.01.033.21.00.050333.11.01.01.01.01.01.01.033.11.0NaN50434.11.01.01.01.01.01.01.034.11.0NaN50532.31.01.01.01.01.01.01.032.31.0NaN50649.51.01.01.01.01.01.01.049.51.00.0\n\n\n\n\nConfidence intervals\nLet’s estimate upper and lower confidence bounds for the CDF function \\(F\\).\n\n\nShow the code\ndfr = hcat(\n    dfr,\n    combine(dfr,\n        [:perc_mean, :perc_std] => ByRow.((m,s) -> m + 2 * s) => :perc_upper_std,\n        [:perc_mean, :perc_std] => ByRow.((m,s) -> m - 2 * s) => :perc_lower_std\n        ),\n    makeunique=true\n)\ndfr = select(dfr, Not(:rel_income_1))\n\n\nlatexstring(raw\"\"\"\n\\mu(P) = \"\"\" * \"$(round(mean(df.perc), digits=2))\" * raw\"\"\"\\quad \\text{and} \\quad\n\\sigma(P) = \"\"\" * \"$(round(std(df.perc), digits=2))\" )\n\n\n\\(\\mu(P) = 0.57\\quad \\text{and} \\quad \\sigma(P) = 0.36\\)\n\n\n\nThis means that on aggregate we have this mental picture of the typical quartile distribution:\n\n\nShow the code\nmu = round(mean(df.perc), digits=2)\n\nsigma = round(std(df.perc), digits=2)\n\nplot(\n    Normal(\n        mu,\n        sigma\n        ),\n        fill=(0, .2, :pink),\n        linecolor=:purple,\n        label=\"\"\"Normal plot \\\\mu = $(mu), \\\\sigma = $(sigma)\"\"\",\n        size=(800, 600),\n        background_color=\"#7711d708\"\n)\n\n\n\n\n\nBut that aggregate picture is not very useful. Let’s look at the distribution by relative income.\n\n\nShow the code\nfunction linspace(start::Any, stop::Any, n::Int)\n    step = (stop - start) / (n - 1)\n    return start:step:stop\nend\n\nfunction diracPlot(x, y, label = \"\")\n    println(\"diracPlot\", x, y, \"arrow from \", x, \",\", y/4, \" to \", x, \",\", y/4)\n    plot!([x,x],[0,y],arrow=true,linewidth=2, label=label)\nend\n\nbins = linspace(minimum(df.rel_income), maximum(df.rel_income), 5)\n\ndfbin = combine(df,\n    :rel_income => ByRow.((x) -> bins[findfirst(bins .>= x)]) => :bin_rel_income,\n    :perc => identity => :perc\n    )\n\ndfgbin = combine(\n    groupby(dfbin, :bin_rel_income),\n    :perc => mean => :perc_mean,\n    :perc => std => :perc_std\n    )\n\np = plot(\n    vline(\n        [mean(df.perc)],\n        label=\"Total Mean\",\n        linestyle=:dash,\n        linewidth=2,\n        ylims=(0, 2.5),\n        legend=:outertopright,\n        background_color=\"#7711d708\"\n        ),\n)\nfor i in 1:size(dfgbin, 1)\n    sstd = dfgbin[i, :perc_std]\n    smean = dfgbin[i, :perc_mean]\n    bin_rel_inc = bins[i]\n    if isnan(sstd) || sstd <= 1e-6\n        diracPlot(smean, 2, \"Group $(i) \\\\mu = $(round(smean, digits=2)) , \\\\sigma = 0\")\n        sstd = 0\n    else\n        vline!(\n        [smean],\n        label=\"\",\n        linewidth=0.5,\n        ylims=(0, 2.5),\n        )\n        plot!(\n        Normal(\n            smean,\n            sstd\n            ),\n            fill=(0, .2),\n            label=\"Group $(i) Normal \\\\mu = $(round(smean, digits=2)), \\\\sigma = $(round(sstd, digits=2))\",\n            size=(800, 600),\n            background_color=\"#7711d708\"\n    )\n    end\n    \nend\n\n@show p\n\n\ndiracPlot0.012arrow from 0.01,0.5 to 0.01,0.5\n\n\n\ndiracPlot1.02arrow from 1.0,0.5 to 1.0,0.5\np = Plot{Plots.GRBackend() n=9}\n\n\n\n\n\n\nThis is just us toying around with the data though, let us now plot the CDF function \\(F\\) and the confidence bounds.\nThose confidence bounds are not very realistic because we treat a variable that’s bounded within \\((0,1)\\) as if it were normally distributed. But it’s a good enough approximation for our purposes.\n\n\nShow the code\n_dfr = dropmissing(sort(dfr, :rel_income))\n\nplot(\n    _dfr.rel_income,\n    _dfr.perc_mean,\n    ribbon=(_dfr.perc_lower_std, _dfr.perc_upper_std),\n    fillalpha=0.2,\n    fillcolor=:blue,\n    label=\"\",\n    xlabel=\"Relative income\",\n    ylabel=L\"Share of population (cdf $\\hat{F}$)\",\n    title=\"Share of population by relative income\",\n    legend=:bottomright,\n    size=(800, 600),\n    ylims=(0, 1.6),\n    xlims=(0, 28),\n    background_color=\"#7711d708\"\n    )\nplot!(\n    _dfr.rel_income,\n    [_dfr.perc_lower_std, _dfr.perc_upper_std],\n    xlims=(0, 28),\n)\n\n\n\n\n\n\nDue to marginalisation across two dimensions, we have a 1D distribution, which we can plot as a curve.\nBut we can clearly see the uncertainty around that curve. Let’s see the quantiles now 🧐\n\n\nShow the code\nplot(\n    _dfr.rel_income,\n    [_dfr.perc_05, _dfr.perc_50, _dfr.perc_95],\n    ribbon=(_dfr.perc_lower_std, _dfr.perc_upper_std),\n    fillalpha=0.2,\n    fillcolor=:blue,\n    label=\"\",\n    xlabel=\"Relative income\",\n    ylabel=L\"Share of population (cdf $\\hat{F}$)\",\n    title=\"Share of population by relative income\",\n    legend=:bottomright,\n    size=(800, 600),\n    ylims=(0, 1.1),\n    xlims=(0, 28),\n    background_color=\"#7711d708\"\n    )"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome to my data notebooks blog !",
    "section": "",
    "text": "This is the first post in my Quarto blog. Welcome ! 👋👋\nThis is “me” in a Picrew avatar below 👇\n\n\n\nThe goal of this small blog is to share my thoughts and ideas about data science, coding, and other things I find interesting. I will also share some of my projects and code snippets. I hope you will enjoy it 🤗.\nI use VSCode and Jupyter to learn Julia bit by bit, and I try to do so using some real world data 😎\n\n\n\nHowever sometimes I might still use ol’ trusty Python 🐍 from time to time (but not R 😅).\n\n\n\n\n\nHere’s a Julia plot of the earth’s GDP growth rate from 1960 to 2019. The data is from the World Bank.\n\n\nShow the code\nusing Plots\nusing DataFrames\nusing CSV\nusing HTTP\nusing ZipFile # for unzipping the file\n\n# download the data\nurl = \"https://api.worldbank.org/v2/en/indicator/NY.GDP.MKTP.KD?downloadformat=csv\";\n\ndownload(url, \"gdp_growth.zip\");\n\n# unzip the file\nr = ZipFile.Reader(\"gdp_growth.zip\");\n\nfor f in r.files\n    if endswith(f.name, \".csv\") && !(startswith(f.name, \"Metadata\"))\n        growthfn = f.name\n        write(open(\"growth.csv\", \"w+\"),read(f, String));\n    end\nend\n\n\n\ndf = DataFrame(CSV.File(\"growth.csv\", header=0, normalizenames=true, silencewarnings=true));\n\n\nworld = df[df[:,1] .== \"World\", :];\n\ngdp = select(world, Not(1:5))\nvecGDP = permutedims(gdp)[:,1]\ndataYears = length(vecGDP)\n\nyears = collect((2021 - dataYears +1):2021);\n\nplot(years, vecGDP, label=\"Total GDP (in 2015 \\$)\", xlabel=\"Year\", ylabel=\"Total GDP (in 2015 \\$)\", legend=:topleft, title=\"Total GDP (in 2015 \\$) from 1968 to 2021\", background_color=\"#7711d708\")\n\n\n\n\n\nCool right ? 😎"
  }
]